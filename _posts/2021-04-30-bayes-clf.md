---
title: "Bayes Classifier for Hackers"
published: false
---

*tldr; this post will cover usage of PyMC3 (python package) for building a (generative) model and classifying data in supervised manner.

DISCLAIMER: Hacker here does not mean Mr. Robot-esque hacking where you break/access systems, sorry to disappoint if you came here wanting to break into systems with Bayes models. Rather, hacker is someone whose natural approach to solving problems is to write code. E.g. simulating probabilities rather than calculating it (as it'll be shown here) or performing tasks by automating it with code. An example of 'way of the hacker' is demonstrated in this [talk](https://www.youtube.com/watch?v=Iq9DzN6mvYA), where he demonstrates we can skip t-test with a hack.

## Motivation of the post
When people talk about machine learning, people always think/mention linear regression, random forest, support vector machines and neural network as that is often the entry point for people into these field, and the gateway tool for machine learning for python users is often [scikit-learn](https://scikit-learn.org/stable/). This was definitely the case for me, and in my continued pursuit to learn more on this field, I have come across the wonderful tool that is Bayesian (Probabilistic) Model, which I'll be sharing in this post how to use it. If you can code you can do bayes modelling (results may vary). For the mathematical purist, feel free to click away now in order to avoid aneurysm for such blasphemy.

In case the disclaimer wasn't clear, this post will avoid any form of maths, but rather dive right into how to use the tool [PyMC3](https://docs.pymc.io) with focus on using it for naives bayes classification. None of the mechanisms that make the inference engine run will be discussed, idea of this post is to get you to use it and love it and become interested enough to learn it to better debug your models. This is the same concept of getting you to drive your car without knowing how it works, and once you have fallen in love with the idea of cars, you'll become a car person (not transformers) and learn everything bout it on your own. 

PyMC3 is probabilistics modelling package in python powered by theano. There is a [wikipedia page](https://en.wikipedia.org/wiki/Probabilistic_programming) listing all the probabilistic programming options out there in case PyMC3 isn't for you.

Below is the structure for this post, feel free to click to the section that is of interest. Let's get started.
### Table of Contents

* [EDA](#eda)

To view the dataset and understand what we are working with. If you are familiar with Iris dataset or have no interest in the dataset, you can skip this section.
* [Thoughts](#conclusion)

Thoughts on the method, such as its advantages/limitations and further reading. If you have no interest beyond the code, feel free to ignore. 
    
* [Glossary](#glossary)

At any point you come across any words you don't understand, here is their brief explanation

### Thoughts <a class="anchor" id="conclusion"></a>

This concludes our journey in using PyMC3 for building a generative model for classifcation, if you made it to the end, I hope you enjoyed the post and this encouraged you to explore more on using this method/tool. There are more advanced usage of bayes modelling which are detailed in [tutorial](https://docs.pymc.io/nb_tutorials/index.html) and [examples](https://docs.pymc.io/nb_examples/index.html) pages of PyMC3 website, one of these "advanced" usage that I particularly enjoy is hierarchical model, maybe I'll write a post of this as well, who knows maybe not.

#### Distributions
One thing to note for some keen observers, there I mention use of this and that distributions. Use of distributions is not set in stone, nor is it something you should (even if you can, I know I have been guilty of it) mess around for achieving the best results. One way to think about what distributions to choose is to understand how the data is generated, simple starting point is discrete vs continuous, always positive or negative is possible. If you are comfortable with reading mathematics you can check out this [post](https://betanalpha.github.io/assets/case_studies/probability_densities.html#1_eye_of_the_tiger) which would introduce you to the different distributions you can employ, or head on over to [PyMC3 docs](https://docs.pymc.io/api/distributions.html) and hack around it. I know I said you shouldn't and at the same time encouraged messing around, if that is confusing, my apologies, but in case this post's take-away isn't clear, you most definitely should just mess around, you learn more by doing rather than reading.

#### Frequentist vs Bayesian
I am not here to pick a side as I am a pragmatist, if it works it works. But this short paragraphy is to clarify for some what are the differences, as I was confused when I first started learning this. 

To explain this briefly, I'll use the example of linear regression model:
* Frequentist approach of building this model would give point estimate(s) for the parameter(s) and confidence intervals, where point estimate means single value. E.g. one coefficient, one value. 
    * Some would be familiar with the term maximum likelihood, that is to say, you obtain the best possible value for the parameter.
* Bayesian appraoch of building this model would generate distributions for the parameters. E.g. one coefficient has a range of values with varying probabilities for the values.
    * that is to say in Bayes, everything is distribution, the model is distributions, the inferred/optimised parameters are distributions (you can fix some values in the model building if desired).

#### Semantics
Some may have noticed I used Bayesian and Probabilistic model interchangebly, they are more or less the same thing, mathematical semantics is always annoying for me personally, but for all intents and purposes, they are the same. Reason for this is output of Bayes models are probabilistic as they generate a distribution, which we can sample from. Another word that is used to describe Bayes model is statistical model, if you come across this term, it can mean Bayes model or it may not. From my understanding, statistical model is a family of mathematical models, and Bayes models is one of them, so calling Bayes model statsitical/mathematical model is correct, but assuming statistical model is Bayes model may not always be correct. 

To sum up, bayes model is a type of statistical model, and statistical models are types of mathematical models. 

#### Advantages
Bayes model are not just limited to classifying, but it can also use the inferred parameters to generate data close to the dataset it learned from. Additionally, the parameters within can be scrutinized for further analysis if desired, given your understanding on the model. 

#### Disadvantage
One thing I have encountered is that, if the dimension of data increases, its performance as a model decreases.

* Generative Model - A model that can be used to generate data, as well as classify things, the inferred parameters can also be used for various things. It is typically a probability model with distributions etc.

### Glossary <a class="anchor" id="glossary"></a>
* Generative Model - A model that can be used to generate data, as well as classify things, the inferred parameters can also be used for various things. It is typically a probability model with distributions etc.
* Machine Learning - Algorithm/Maths that learns the pattern of the data.
* Probabilistic Programming - Tool/language for building probabilistic models. 
* Inference Engine - The machinery that makes the inference, where inference means obtaining (inferring) the parameters behind the distribution/model.
* Theano - I want to say it is NumPy on steroids, I don't know enough to comment beyond that.

```python
## import all the things
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns; sns.set()

import pymc3 as pm
import theano.tensor as tt
import theano
theano.config.gcc.cxxflags = "-Wno-c++11-narrowing"

import sklearn.datasets as data
from sklearn.model_selection import train_test_split

from scipy.stats import multivariate_normal, norm

from sklearn.metrics import accuracy_score, roc_auc_score
```
